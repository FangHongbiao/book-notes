



 [官网地址]( https://nsq.io/overview/quick_start.html )

# OVERVIEW 

## QUICK START

1. 安装NSQ， [地址]( https://nsq.io/deployment/installing.html )

2. in one shell, start `nsqlookupd`:

   ```
   $ nsqlookupd
   ```

3. in another shell, start `nsqd`:

   ```
   $ nsqd --lookupd-tcp-address=127.0.0.1:4160
   ```

4. in another shell, start `nsqadmin`:

   ```
   $ nsqadmin --lookupd-http-address=127.0.0.1:4161
   ```

5. publish an initial message (creates the topic in the cluster, too):

   ```
   $ curl -d 'hello world 1' 'http://127.0.0.1:4151/pub?topic=test'
   ```

6. finally, in another shell, start `nsq_to_file`:

   ```
   $ nsq_to_file --topic=test --output-dir=/tmp --lookupd-http-address=127.0.0.1:4161
   ```

7. publish more messages to `nsqd`:

   ```
   $ curl -d 'hello world 2' 'http://127.0.0.1:4151/pub?topic=test'
   $ curl -d 'hello world 3' 'http://127.0.0.1:4151/pub?topic=test'
   ```

8. to verify things worked as expected, in a web browser open `http://127.0.0.1:4171/` to view the `nsqadmin` UI and see statistics. Also, check the contents of the log files (`test.*.log`) written to `/tmp`.

## FEATURES & GUARANTEES

 NSQ是一个实时分布式消息传递平台

1. Features

   1.  支持没有SPOF (Single Point Of Failure, 单点故障) 的分布式拓扑 
   2.  水平扩展 (没有brokers ，无缝地向集群添加更多节点) 
   3. 基于消息传递的低延迟push
   4.  组合负载平衡和多播样式的消息路由 
   5.  擅长面向流(高吞吐量)和面向job(低吞吐量)的工作负载 
   6.  主要在内存中(高水位标记之外的消息透明地保存在磁盘上) 
   7.  运行时发现服务，供消费者者查找生产者([nsqlookupd](https://github.com/nsqio/nsq/tree/master/nsqlookupd/README.md) ) 
   8.  传输层安全性(TLS) 
   9.  data format agnostic 
   10.  很少的依赖项(易于部署)和一个健全的、有限的默认配置
   11.  简单的TCP协议支持任何语言的客户端库 
   12. 用于统计、管理操作和生产者的HTTP接口(发布消息不需要客户端库)  
   13.  与``statsd`集成，实现实时检测 
   14.  健壮的集群管理接口(nsqadmin) 

2. ### Guarantees

   1.  消息**不是**持久的(默认情况下) 
   2.  消息至少传递一次 
   3.  接收到的消息是无序的 
   4.  消费者**最终**会找到所有的主题生产者 

3. FAQ

   1. #### Deployment

      1.  nsqd的推荐拓扑是什么?
      2.  为什么`nsqlookupd`不能被生产者用来查找发布到哪里? 
      3.   我只想使用`nsqd`作为单个节点上的工作队列，这是一个合适的使用场景吗? 
      4.   我应该运行多少个nsqlookupd ? 
      
   2. #### Publishing
   
      1.  我需要一个客户端库来发布消息吗? 
   
      2.  为什么要强制客户端处理对TCP协议的PUB和MPUB命令的响应? 
   
      3.  When can a `PUB` or `MPUB` fail? 
   
         1. The topic name is not formatted correctly (to character/length restrictions). See the [topic and channel name spec](https://nsq.io/clients/tcp_protocol_spec.html#notes).
         2. The message is too large (this limit is exposed as a parameter to `nsqd`).
         3. The topic is in the middle of being deleted.
         4. `nsqd` is in the middle of cleanly exiting.
         5. Any client connection-related failures during the publish.
   
         (1) and (2) should be considered programming errors. (3) and (4) are rare and (5) is a natural part of any TCP based protocol.
   
      4.  How can I mitigate scenario (3) above?
   
   3. #### Design and Theory
   
      1.  如何为主题和通道命名? 
   
         1. A topic name should describe the *data in the stream*.
         2. A channel name should describe the *work performed* by its consumers.
         3. For example, good topic names are `encodes`, `decodes`, `api_requests`, `page_views` and good channel names are `archive`, `analytics_increment`, `spam_analysis`.
   
      2.  单个nsqd可以支持的主题和通道的数量有限制吗? 
   
          没有内置的限制。它只受运行nsqd的主机的内存和CPU的限制 
   
      3.  如何向集群发布/t通告新主题?
   
          第一个`PUB`或`SUB`将在nsqd上创建主题。然后，主题元数据将传播到配置的`nsqlookupd`。其他读者将通过定期查询`nsqlookupd`来发现这个主题。  
   
      4.  NSQ可以做RPC吗? 
   
   5. #### pynsq Specific
   
## DESIGN

NSQ是simplequeue (simplehttp的一部分)的继承者，因此被设计成: 

	-  支持高可用性和消除SPOFs的拓扑 
	-   解决对更强的消息传递保证的需求 
	-   限制单个进程的内存占用(通过将一些消息持久化到磁盘) 
	-   极大地简化了生产者和消费者的配置需求 
	-   提供一个简单的升级路径 
	-   提供一个简单的升级路径 

###  Simplifying Configuration and Administration

1. 一个 `nsqd` 实例被设计成同时处理多个数据流。streams被称为`topics`, 并且一个 topic有一个或多个`channels`。每个channel接收一个主题所有消息的一个备份。在实践中，一个channel  映射到使用主题的下游服务。 

2.  topics 和 channel 不是预先配置的。

   topics被首次创建当发生如下情况：

   1. publish 到一个命名topic
   2.  subscribe指定topic的channel。 

   channel 被首次创建当订阅指定的频道。 

3.  topic 和 channel 的所有缓冲数据都是相互独立的，这样可以防止速度较慢的 consumer  造成其他channel 的积压(在topic 级别也是如此)。 

4. 一个 channel 可以有 (通常也确实有) 多个客户端连接。假设所有已连接的客户端处于可接收消息的状态，那么每条消息将被随机分发给其中一个客户端

   ![f1434dc8-6029-11e3-8a66-18ca4ea10aca](F:\PersonPorject\book-notes\NSQ\img\f1434dc8-6029-11e3-8a66-18ca4ea10aca.gif)

5. topic -> 角度来看， 消息是多播的(每个通道接收到一个主题所有消息的一个副本)； 但是从channel -> consumers角度来看，每个消费者只接收到了那个通道一部分消息

6. NSQ 包含了一个辅助应用， `nsqlookup`，其提供了目录服务，该目录服务支持consumer查询可以提供他们想要订阅的topic的 `nsqd`实例的地址。 在配置方面，这将 producer 与 consumer 分离(它们都单独地只需要知道在哪里联系公共的 nsqlookupd 实例，而不需要相互联系)，从而降低了复杂性和维护。 

7. 从较低的基本来看， `nsqd`和`nsqlookupd`保护着一个 TCP 长连接， `nsqd`通过该连接定期推送自己的状态到 `nsqlookupd`。 此数据用于通知`nsqlookupd`将向consumer提供哪些`nsqd`地址。  对于消费者来说，有一个公开的HTTP endpoint `/lookup`用于轮询。 

8.  要引入某个主题的新的不同消费者，只需启动一个NSQ客户端，该客户端使用`nsqlookupd`实例的地址配置。不需要更改配置就可以添加新的使用者或新的发布者，从而大大降低了开销和复杂性。 

9. 注意： 未来的版本中，用于返回地址的启发式`nsqlookupd`可以基于深度、连接的客户端数量或其他“智能”策略。  当前的实现就是 `ALL`。最终的目标是确保所有生产者都是从深度接近于零的地方读取的。 

10.  需要注意的是，`nsqd`和`nsqlookupd`守护进程被设计为独立操作，没有兄弟姐妹之间的通信或协调。 

11.  我们还认为，有一种查看、内省和总体管理集群的方法是非常重要的。 

     `nsqadmin` 被用于做这件事。它提供了Web UI  浏览主题/频道/消费者的层次结构，并检查每个层的深度和其他关键统计信息 。 此外，它还支持一些管理命令，比如删除和清空通道 ( 当可以安全地丢弃通道中的消息以将深度恢复到0时，该命令是有用的 )

### Straightforward Upgrade Path

1.  这是最重要的特性之一。我们的生产系统处理大量的流量，所有这些流量都建立在现有的消息传递工具上，因此我们需要一种方法来地升级我们基础设施的特定部分，并且几乎不受影响。 

2. 步骤

   1.  首先，在消息生产者端，我们构建`nsqd`来匹配`simplequeue`。具体地说，`nsqd`公开一个`HTTP /put` endpoint，就像`simplequeue`一样，用于发布二进制数据(但有一点需要注意，endpoint需要指定一个额外的“topic”查询参数)。想要切换到开始发布到nsqd的服务只需要对代码做一些小的修改。 

   2.  其次，我们用Python和Go构建了与我们在现有库中习惯的功能和习惯用法相匹配的库。通过将代码更改限制为引导，这简化了消息使用者方面的转换。所有业务逻辑保持不变 

   3.  最后，我们构建了一些实用程序来将新旧组件粘合在一起。这些都可以在库中的示例目录中找到: 

      - `nsq_pubsub` - expose a `pubsub` like HTTP interface to topics in an **NSQ** cluster

      - `nsq_to_file` - durably write all messages for a given topic to a file

      - `nsq_to_http` - perform HTTP requests for all messages in a topic to (multiple) endpoints

###  Eliminating SPOFs 

1. NSQ被设计成以分布式方式使用。nsqd客户端(通过TCP)连接到提供指定主题的所有实例。没有中间人，没有消息代理，也没有SPOFs![tumblr_mat85kr5td1qj3yp2](F:\PersonPorject\book-notes\NSQ\img\tumblr_mat85kr5td1qj3yp2.png)
2.   This topology eliminates the need to chain single, aggregated, feeds.  而是直接从**所有**生产者那里消费。从技术上讲，无论哪个客户端连接到哪个NSQ，只要有足够多的客户端连接到所有生产者以满足消息量，就可以保证所有这些最终都会被处理。 
3.  对于`nsqlookupd`，高可用性是通过运行多个实例实现的。  它们之间不直接通信，数据最终被认为是一致的。 使用者轮询所有已配置的nsqlookupd实例，并合并响应。 过时，无法访问或其他故障的节点不会使系统陷入瘫痪。

### Message Delivery Guarantees

1.  NSQ保证一个消息将被传递至少一次，尽管重复的消息是可能的。消费者应该预料到这一点并进行反欺骗或执行幂等操作。 
2.  此保证作为协议的一部分执行，工作如下(假设客户端已成功连接并订阅了主题): 
   1.  客户端表明他们已经准备好接收消息 
   2.  NSQ发送消息并临时在本地存储数据(在重新排队或超时的情况下) 
   3.  客户端回复FIN(完成)或REQ(重新排队)，表示成功或失败。如果客户端没有回复，NSQ将在配置的超时时间后超时，并且自动重新入队
3.  这确保了惟一会导致消息丢失的边缘情况是`nsqd`进程的非正常关闭。在这种情况下，内存中的任何消息(或没有刷新到磁盘的任何缓冲写)都将丢失。
4.  如果防止消息丢失是最重要的，那么即使是这种边缘情况也可以被减轻。   一种解决方案是建立冗余的`nsqd`对，让接收同一部分消息的副本的冗余(在不同的主机上)。因为您已经将消费者编写为幂等的，所以对这些消息进行两次处理不会对下游产生影响，并且允许系统在不丢失消息的情况下忍受任何单个节点故障。 
5.  结论是，NSQ提供了构建块来支持各种生产用例和可配置的持久性程度。 

### Bounded Memory Footprint

1. `nsqd` 提供了配置选项 ` --mem-queue-size `, 用于 确定对于给定队列保存在内存中的消息数量。  如果队列的深度超过此阈值，则将消息透明地写入磁盘。 这限制了给定nsqd进程的内存占用为：`mem-queue-size * #_of_channels_and_topics`

   ![tumblr_mavte17V3t1qj3yp2](F:\PersonPorject\book-notes\NSQ\img\tumblr_mavte17V3t1qj3yp2.png)

2.  而且，敏锐的观察者可能已经发现，通过将这个值设置为较低的值(如1或甚至0)，可以方便地获得更高的交付保证。  磁盘支持的队列被设计为可以解决非正常的重启带来的消息丢失问题(尽管消息可能被传递两次)。 

3.  此外，与消息传递保证相关，正常关闭(通过发送`nsqd`进程 `TERM`信号)可以安全地将当前保存在内存中、在运行中、在延迟中以及在各种内部缓冲区中的消息。 

4.  注意， `topic/channel` 名称以字符串`#ephemeral`结尾的将不会被缓冲到磁盘上，而是在传递了内存队列大小 `mem-queue-size` 之后删除消息。 这使不需要消息保证的用户可以订阅频道。 在其最后一个客户端断开连接后，这些临时通道也将消失。 对于临时主题，这意味着已创建，使用和删除了至少一个频道（通常是一个临时频道）。

### Efficiency

1. NSQ 被设计成通过`memcached-like`命令协议上通信，同时带有简单的 `size-prefixed`响应。所有消息数据都保存在核心中，包括尝试次数、时间戳等元数据。  这消除了在服务器和客户机之间来回复制数据的情况, 这是之前工具链在重新入队时的国有属性。 这也简化了客户机，因为它们不再需要负责维护消息状态。 
2.  此外，通过减少配置复杂性，` setup and development `时间也会大大减少(特别是在主题有>1消费者的情况下)。 
3.  对于数据协议，我们做了一个关键的设计决策，通过将数据推送到客户端而不是等待它被拉出，从而最大化性能和吞吐量。 (**采用的是PUSH方式**)。 这个概念，我们称之为`RDY`状态，本质上是客户端流控制的一种形式。 
4.  当客户端连接到`nsqd`并订阅通道时，它处于`RDY`状态0。  这意味着不会向客户机发送任何消息。当客户机准备接收消息时，它发送一个命令，将其RDY状态更新到某个它准备处理的数量，比如100。 不需要任何额外的命令，100条可用的消息将被推送到客户机(每次减少该客户机在服务器端`RDY`计数)。 ![tumblr_mataigNDn61qj3yp2](F:\PersonPorject\book-notes\NSQ\img\tumblr_mataigNDn61qj3yp2.png)
5.  客户端库被设计用来发送一个命令来更新`RDY`计数，当它达到可配置的` max-in-flight `的25%时(适当地分配到多个nsqd实例的连接)。 这是一个重要的性能调优选项，因为一些下游系统能够更容易地批处理消息，并从更高的` max-in-flight `中获益。 
6.  Notably, because it is both buffered *and* push based with the ability to satisfy the need for independent copies of streams (channels), we’ve produced a daemon that behaves like `simplequeue` and `pubsub` *combined* . This is powerful in terms of simplifying the topology of our systems where we would have traditionally maintained the older toolchain discussed above. 

### Go

1.  关于NSQ, Go channel(不要与NSQ channel混淆)和该语言的内置并发特性非常适合nsqd的内部工作。我们利用缓冲通道来管理内存中的消息队列，并无缝地将溢出写入磁盘。 
2.  标准库简化了网络层和客户端代码的编写。内建的内存和cpu性能分析钩子突出了优化的机会，并且只需很少的集成工作。 我们还发现在隔离状态下测试组件、使用接口进行模拟类型测试以及迭代构建功能非常容易。 

## INTERNALS

 NSQ由3个守护进程组成: 

1. `nsqd`：  接收、排队并将消息传递给客户端。 

 	2.  `nsqlookupd`： 管理拓扑信息并提供最终一致的发现服务。 
 	3.  `nsqadmin`： 用于实时监控集群(并执行各种管理任务)的web UI。 

 NSQ中的数据流被建模为流和消费者的树。主题是不同的数据流。通道是订阅给定主题的使用者的逻辑分组。 ![f1434dc8-6029-11e3-8a66-18ca4ea10aca](F:\PersonPorject\book-notes\NSQ\img\f1434dc8-6029-11e3-8a66-18ca4ea10aca.gif)

 单个nsqd可以有多个主题，每个主题可以有多个通道。  通道接收主题的所有消息的副本，支持多播风格的传递，而通道上的每个消息都分布在其订阅者之间，支持负载平衡。 

这些原语形成了一个强大的框架来表达各种简单和复杂的拓扑。
有关NSQ设计的更多信息，请参阅设计文档 [design doc](http://nsq.io/overview/design.html). 。

### Topics and Channels

1.  主题和频道是NSQ的核心原语，最好地例证了系统的设计如何无缝地转换到Go的特征。 

2. Go的channel是一种自然的表达队列的方式， 因此，NSQ topic/channel 的核心就是一个 `Message` 指针的 `buffered go-chan`。buffer的大小等于配置参数中的  `mem-queue-size `

3.  在离线读取数据之后，将消息发布到主题的行为包括: 

   1. instantiation of a `Message` struct (and allocation of the message body `[]byte`)
   2. read-lock to get the `Topic`
   3. read-lock to check for the ability to publish
   4. send on a buffered go-chan

4. 为了从主题 topic 拿到消息发送到 channels， 主题不能依赖典型的 go-chan 接收语义， 因为在go-chan上接收的多个goroutines会分发消息，而期望的最终结果是将每个消息复制到每个通道 

5.  每个 topic 维护3个主要goroutines

   1.  ` router `: 负责从传入的go-chan读取新发布的消息并将其存储在队列(内存或磁盘)中。 
   2. ` messagePump `: 负责将信息复制并推送到上面描述的信道。 
   3.  `DiskQueue`  : 负责`DiskQueue `IO 

6.  通道稍微复杂一些，但是共享了暴露单个输入和单个输出go-chan的基本目标(从内部抽象出消息可能在内存或磁盘中的事实)

   ![682fc358-5f76-11e3-9b05-3d5baba67f13](F:\PersonPorject\book-notes\NSQ\img\682fc358-5f76-11e3-9b05-3d5baba67f13.png) 

7. 此外，每个通道维护2个按时间排序的优先级队列，负责延迟和动态消息超时(以及2个相应的goroutine，用于监视它们)。 

8. 通过管理每个通道的数据结构，而不是依赖于Go运行时的全局计时器调度器，并行化得到了改进。 

9.  **Note:** Internally, the Go runtime uses a single priority queue and goroutine to manage timers. This supports (but is not limited to) the entirety of the `time` package. It normally obviates the need for a *user-land* time-ordered priority queue but it’s important to keep in mind that it’s a *single* data structure with a *single* lock, potentially impacting `GOMAXPROCS > 1` performance. See [runtime/time.go](http://golang.org/src/pkg/runtime/time.go?s=1684:1787#L83). 

### Backend / DiskQueue

1. NSQ的设计目标之一是限制内存中的消息数量。它通过DiskQueue( which owns the *third* primary goroutine for a topic or channe )透明地将消息溢出写入磁盘来实现这一点 

2. 由于内存队列只是一个go-chan，它是琐碎的路由消息到内存，如果可能的话，然后回退到磁盘: 

    ```go
    for msg := range c.incomingMsgChan {
        select {
        case c.memoryMsgChan <- msg:
        default:
            err := WriteMessageToBackend(&msgBuf, msg, c.backend)
            if err != nil {
                // ... handle errors ...
            }
        }
    }
    ```

3. NSQ也有临时主题/通道的概念。它们丢弃消息溢出(而不是写入磁盘)，并在不再有客户端订阅时消失。 这是Go接口的一个完美用例。  主题和通道的结构成员声明为后端接口，而不是具体类型。普通的主题和通道使用磁盘队列，而临时的则使用DummyBackendQueue存根，后者实现了一个无操作后端。 

### Reducing GC Pressure

1.  在任何垃圾收集环境中，您都会受到吞吐量(做有用的工作)、延迟(响应性)和常驻集大小(占用空间)之间的压力。 
2.  到Go 1.2时，GC是标记-清楚(并行)的、非分代的、非压缩的、停止-世界的，而且基本精确的。 它基本精确的，因为剩余的工作没有及时完成(它被安排在Go 1.3中)。  
3.  Go GC肯定会继续改进，但普遍的事实是:创建的垃圾越少，收集的时间就越少。 
4. 首先，了解GC在实际工作负载下的行为非常重要。为此，`nsqd`以`statsd`格式(与其他内部度量一起)发布GC统计信息。`nsqadmin`显示这些指标的图表，让您了解GC在频率和持续时间方面的影响。
5.  为了真正减少垃圾，你需要知道垃圾是在哪里产生的。Go工具链再次提供了答案: 
   1.  使用`test`包并执行`go test -benchmem`来对热代码路径进行基准测试。它分析了每个迭代的分配数量(基准测试运行可以通过benchcmp进行比较)。 
   2.  Build using `go build -gcflags -m`, which outputs the result of [escape analysis](http://en.wikipedia.org/wiki/Escape_analysis). 
6.  考虑到这一点，下面的优化对`nsqd`非常有用: 
   1. Avoid `[]byte` to `string` conversions.
   2. Re-use buffers or objects (and someday possibly [`sync.Pool`](https://groups.google.com/forum/#!topic/golang-dev/kJ_R6vYVYHU) aka [issue 4720](https://code.google.com/p/go/issues/detail?id=4720)).
   3. Pre-allocate slices (specify capacity in `make`) and always know the number and size of items over the wire.
   4. Apply sane limits to various configurable dials (such as message size).
   5. Avoid boxing (use of `interface{}`) or unnecessary wrapper types (like a `struct` for a “multiple value” go-chan).
   6. Avoid the use of `defer` in hot code paths (it allocates).

### TCP Protocol

1.  NSQ TCP协议是一个很好的例子，在这个章节中，这些GC优化概念得到了很好的利用。 

2. 主要优化的是跟 `[] byte`有关， 避免生成字符串造成GC压力

   1.  avoid the [`encoding/binary`](http://golang.org/pkg/encoding/binary/) package’s convenience [`Read()`](http://golang.org/pkg/encoding/binary/#Read) and [`Write()`](http://golang.org/pkg/encoding/binary/#Write) wrappers (and their extraneous interface lookups and conversions) and instead call the appropriate [`binary.BigEndian`](http://golang.org/pkg/encoding/binary/#ByteOrder) methods directly. 

   2.   since data read from the socket is stored as `[]byte`, rather than produce garbage by allocating `string` keys, and to avoid a copy from the slice to the backing array of the `MessageID`, the `unsafe` package is used to cast the slice directly to a `MessageID`: 

      ```go
      id := *(*nsq.MessageID)(unsafe.Pointer(&msgID))
      ```

   3.  In order to avoid `string` allocations, **nsqd** uses a [custom base 10 conversion method](https://github.com/nsqio/nsq/blob/master/internal/protocol/byte_base10.go#L9-L29) that operates directly on a `[]byte` 

### HTTP

1.  NSQ的HTTP API建立在Go的`net/http`包之上。因为它只是HTTP，所以几乎可以在任何现代编程环境中使用它，而不需要特殊的客户端库。 

2.  它的简单性掩盖了它的强大功能，因为Go的HTTP工具箱最有趣的方面之一就是它所支持的广泛的调试功能。  The [`net/http/pprof`](http://golang.org/pkg/net/http/pprof/) package integrates directly with the native HTTP server, exposing endpoints to retrieve CPU, heap, goroutine, and OS thread profiles. These can be targeted directly from the `go` tool: 

   ```go
   go tool pprof http://127.0.0.1:4151/debug/pprof/profile
   ```

3.  此外，`/stats`endpoint 以  `JSON or pretty-printed text` 形式返回大量指标，这使得管理员可以很容易地从命令行进行实时检测: 

   ```go
   watch -n 0.5 'curl -s http://127.0.0.1:4151/stats | grep -v connected'
   ```

4.  Finally, each new Go release typically brings [measurable performance gains](https://github.com/davecheney/autobench). It’s always nice when recompiling against the latest version of Go provides a free boost! 

### Dependencies

There are two main schools of thought:

1. **Vendoring**: copy dependencies at the correct revision into your application’s repo and modify your import paths to reference the local copy.
2. **Virtual Env**: list the revisions of dependencies you require and at build time, produce a pristine `GOPATH` environment containing those pinned dependencies.

### Testing

1. there was one aspect of the initial implementation that became problematic for testing: global state. 
2.  To resolve this, a `Context` struct is passed around that contains configuration metadata and a reference to the parent **nsqd**. All references to global state were replaced with this local `Context`, allowing children (topics, channels, protocol handlers, etc.) to safely access this data and making it more reliable to test. 

### Robustness

1.  在面对不断变化的网络条件或意外事件时不够健壮的系统在分布式生产环境中表现不好。 
2.  NSQ的设计和实现允许系统容忍失败，并以一致的、可预测的和不足为奇的方式运行。 
3.  总的原则是快速失败，将错误视为致命的，并提供一种方法来调试确实发生的任何问题。 
4.  但是，为了做出反应，你需要能够探测到异常情况 

#### Heartbeats and Timeouts

1.  NSQ TCP协议是面向推的。连接、握手和订阅之后，消费者处于RDY状态0。当消费者准备接收消息时，它将RDY状态更新为愿意接收的消息数量。NSQ客户端库不断地在幕后管理这些，从而产生了一个流控制的消息流。 
2.  `nsqd`将定期通过连接发送一个心跳。客户端可以配置心跳之间的间隔，但是`nsqd`在发送下一个心跳之前需要一个响应。 
3.  应用程序级心跳和RDY状态的组合避免了 [head-of-line blocking](http://en.wikipedia.org/wiki/Head-of-line_blocking) ，其可能会使心跳变得无效( 也就是说，如果消费者在处理消息流时落后了，操作系统的接收缓冲区就会被填满，从而阻塞心跳 )
4.   为了保证进度，所有网络IO都与配置的心跳间隔的截止日期绑定在一起。这意味着您完全可以断开nsqd和使用者之间的网络连接，它将检测并正确处理错误。 
5.  当检测到致命错误时，将强制关闭客户端连接。正在运行的消息超时并重新排队交付给另一个使用者。最后，记录错误并增加各种内部度量。 

#### Managing Goroutines

1.  启动goroutines非常简单。不幸的是，要协调他们的清理工作并不那么容易。避免死锁也是一个挑战。这通常归结为一个排序问题，即在go-chan上接收的goroutine在上游goroutine发送之前就退出了。
2.  为什么要关心这些呢?很简单，孤立的goroutine是内存泄漏。在长时间运行的守护进程中出现内存泄漏是很糟糕的，特别是当其他所有操作都失败时，需要保证您的进程应该是稳定的。 
3.  更复杂的是，一个典型的`nsqd`流程在消息传递中包含许多goroutine。在内部，消息“所有权”经常改变。为了能够干净地关闭，对所有进程内的消息负责是非常重要的。 
4.  虽然没有什么灵丹妙药，但是下面的技巧可以使它更容易管理…… 

    1. WaitGroups

    2. Exit Signaling

    3. Synchronizing Exit

    4. Logging





# COMPONENTS 

## nsqd

1. `nsqd`是负责接收、排队、传递消息给客户端的守护进程
2. `nsqd`可以运行在`standalone`模式，但是通常通过`nsqlookupd`实例配置在集群里。
3.  它监听两个TCP端口，一个用于客户端，另一个用于HTTP API。它可以选择监听第三个HTTPS端口。 

### [Command Line Options]( https://nsq.io/components/nsqd.html )

### HTTP API

### Debugging and Profiling

`nsqd` provides a suite of profiling endpoints that integrate directly with Go’s [pprof](http://golang.org/pkg/net/http/pprof/#pkg-overview) tool. If you have the go tool suite installed, simply run:

```
# memory profiling
$ go tool pprof http://localhost:4151/debug/pprof/heap

# cpu profiling
$ go tool pprof http://localhost:4151/debug/pprof/profile
```

### TLS

### [AUTH](https://nsq.io/components/nsqd.html#auth)

### End-to-End Processing Latency

### Statsd / Graphite Integration

## nsqlookupd

nsqlookupd是管理拓扑信息的守护进程。客户端查询`nsqlookupd`来发现特定主题的`nsqd`生产者，而`nsqd`节点负责广播主题和频道信息 

有两个接口: `nsqd`用于广播的TCP接口和客户端用户执行发现和管理操作的HTTP接口。 

### Command Line Options

### [HTTP Interface](https://nsq.io/components/nsqlookupd.html#http-interface)

### Deletion and Tombstones

1. 当一个主题在全局范围内都不在被生产时， 从集群里清除它的信息是一个相对简单的操作。假设所有生产消息的应用程序都down了， 在`nsloopupd`实例上使用 `/delete_topic` endpoint 就可以完成操作( 在内部，它将识别相关的nsqd生产者，并在这些节点上执行适当的操作 )
2. 对于一个全局channel的删除是类似的， 唯一的不同是使用`delete_channel`。  需要确保订阅了该通道的所有使用者都已被关闭 
3.  但是，当不再在节点的子集上生成主题时，就会变得更加复杂。  由于消费者查询nsqlookupd并连接到所有生产者的方式，您将进入竞争条件，尝试从集群中删除信息，而消费者发现该节点并重新连接(从而推动更新，使得主题仍然在该节点上生成) 。 在这些情况下，解决方案是使用`tombstone`。  `nsqlookupd`上下文中的`tombstone`是特定于生产者的，并且可以持续一段可配置的—— `tombstone-lifetime `。 
4.  在该窗口期间，不会在`/lookup`查询中列出生产者，允许节点删除主题，将该信息传播到`nsqlookupd `( which then *removes* the tombstoned producer )，并防止任何使用者重新发现该节点。 

## nsqadmin

1.  `nsqadmin`是一个Web UI，用于实时查看聚合的集群状态并执行各种管理任务。 

### Command Line Options

## utilities

1. ### nsq_stat 

   ### Polls `/stats` for all the producers of the specified topic/channel and displays aggregate stats 

2. ### nsq_tail

   Consumes the specified topic/channel and writes to stdout (in the spirit of tail(1))

3. ### nsq_to_file

   Consumes the specified topic/channel and writes out to a newline delimited file, optionally rolling and/or compressing the file.

4. ### nsq_to_http

   Consumes the specified topic/channel and performs HTTP requests (GET/POST) to the specified endpoints.

5. nsq_to_nsq[Anchor link for: nsq_to_nsq](https://nsq.io/components/utilities.html#nsq_to_nsq)

   Consumes the specified topic/channel and re-publishes the messages to destination `nsqd` via TCP.

6. ### to_nsq

   Takes a stdin stream and splits on newlines (default) for re-publishing to destination `nsqd` via TCP.

# CLIENTS (Lib)

在NSQ的设计中，将很多的责任推到了客户端库上面， 为了保持整体集群的鲁棒性和性能。

 本指南试图概述行为良好的客户端库需要完成的各种职责。 因为发布消息到 `nsqd`是非常简单的(仅仅通过 HTTP POST 请求到 `/put` endpoint 就可以)， 本文档关注的是消费者。

By setting these expectations we hope to provide a foundation for achieving consistency across languages for NSQ users.

### [Overview](https://nsq.io/clients/building_client_libraries.html#overview)

1. [Configuration](https://nsq.io/clients/building_client_libraries.html#configuration)
2. [Discovery](https://nsq.io/clients/building_client_libraries.html#discovery) (optional)
3. [Connection Handling](https://nsq.io/clients/building_client_libraries.html#connection_handling)
4. [Feature Negotiation](https://nsq.io/clients/building_client_libraries.html#feature_negotiation)
5. [Data Flow / Heartbeats](https://nsq.io/clients/building_client_libraries.html#data_flow)
6. [Message Handling](https://nsq.io/clients/building_client_libraries.html#message_handling)
7. [RDY State](https://nsq.io/clients/building_client_libraries.html#rdy_state)
8. [Backoff](https://nsq.io/clients/building_client_libraries.html#backoff)
9. [Encryption/Compression](https://nsq.io/clients/building_client_libraries.html#encryptioncompression)

### Configuration

1.  在较高的层次上，我们关于配置的设计理念是设计一个系统，使其具有支持不同工作负载的灵活性，使用“开箱即用”的默认设置可以运行良好，并最小化`dial`数量。

2.   消费者通过到`nsqd`实例的TCP连接订阅通道上的主题。每个连接只能订阅一个主题，因此多个主题消费需要相应地构建多个连接。

3.  使用`nsqlookupd`用于发现是可选的， 因此客户端库应当支持一些配置：

   1. 消费者直连到一个或多个`nsqd`实例
   2. 轮询一个或过个`nsqlookupd`实例

   当消费者被配置为轮询`nsqlookupd`时，轮询间隔应该是可配置的。另外， 因为NSQ的典型部署是在有许多生产者和消费者的分布式环境中， 客户端库应该根据配置值的随机的抖动值(概率 % )自动添加抖动。  This will help avoid a thundering herd of connections. For more detail see [Discovery](https://nsq.io/clients/building_client_libraries.html#discovery).

4.  对于使用者来说，一个重要的性能旋钮是在`nsqd`期望响应之前它可以接收到的消息的数量。  这种流水线简化了缓冲、批处理和异步消息处理。  按照惯例，这个值称为`max_in_flight`，它影响RDY状态的管理方式。有关详细信息，请参见 [RDY State](https://nsq.io/clients/building_client_libraries.html#rdy_state)。 

5.  作为一个被设计为优雅地处理失败的系统，客户端库应该实现对失败消息的重试处理，并 根据每个消息的尝试次数限制该行为的选项。 For more detail see [Message Handling](https://nsq.io/clients/building_client_libraries.html#message_handling). 

6.  当消息处理失败时，客户端库将自动处理重新排队的消息。 NSQ支持使用`REQ`命令发送延迟。  客户端库应该提供选项，以确定最初应该将延迟设置为什么(对于第一次故障)，以及如何更改后续故障的延迟。  For more detail see [Backoff](https://nsq.io/clients/building_client_libraries.html#backoff). 

7.  最重要的是，客户端库应该支持为消息处理配置回调处理程序的一些方法。 这些回调的签名应该很简单，通常只接受一个参数(“ message object” 的实例)。  

### Discovery

1. NSQ 一个重要的组件是 `nsqlookupd`， 它为消费者提供了一种发现服务，使得消费者可以在运行时定位提供给定主题的`nsqd`

2. 虽然是可选的，使用`nsqlookupd`极大地减少了用于维护和扩展大规模分布式NSQ集群所需要的配置信息

3. 当消费者使用`nsqlookupd`用于发现时， 客户端库应当：

   1. 管理轮询所有`nsqlookupd`实例用于获得最新的提供给定主题的`nsqd`集合的过程
   2. 管理与这些`nsqd`的连接

4. 查询`nsqlookupd`实例非常简单。执行一个HTTP请求到查询endpoint，带上查询参数，查询参数为消费者想要发现的主题, 例如 `/lookup?topic=clicks`。响应的格式是 JSON

   ```json
   {
       "channels": ["archive", "science", "metrics"],
       "producers": [
           {
               "broadcast_address": "clicksapi01.routable.domain.net",
               "hostname": "clicksapi01.domain.net",
               "remote_address": "172.31.27.114:51996",
               "tcp_port": 4150,
               "http_port": 4151,
               "version": "1.0.0-compat"
           },
           {
               "broadcast_address": "clicksapi02.routable.domain.net",
               "hostname": "clicksapi02.domain.net",
               "remote_address": "172.31.34.29:14340",
               "tcp_port": 4150,
               "http_port": 4151,
               "version": "1.0.0-compat"
           }
       ]
   }
   ```

   

5.  `broadcast_address` 和`tcp_port` 被用来连接`nsqd`。按照设计， `nsqlookupd`实例之间并不共享和协调它们各自的数据，因此客户端库应当将它们从所有`nslookupd`查询接收到的`nsq`列表进行合并，并构建最终连接的`nsq`列表。 `broadcast_address:tcp_port `的组合被用作合并的key

6.  应该使用定时器来重复轮询已配置的`nsqlookupd`，以便消费者自动发现新的`nsqd`。客户端库应该自动初始化到所有新发现实例的连接。 

7.  当客户端库执行开始时，它应该通过向配置的`nsqlookupd`实例启动一组初始请求来引导这个轮询过程。 

### Connection Handling

1.  一旦消费者有了要连接的`nsqd`(通过发现或手动配置)，就应该打开到`broadcast_address:port`的TCP连接。对于消费者希望订阅的每个主题，应该与每个`nsqd`建立单独的TCP连接。 
2.  当连接到一个`nsqd`实例时，客户端库应该发送以下数据，顺序如下: 

   1. the magic identifier
   2. an `IDENTIFY` command (and payload) and read/verify response (see [Feature Negotiation](https://nsq.io/clients/building_client_libraries.html#feature_negotiation))
   3. a `SUB` command (specifying desired topic) and read/verify response
   4. an initial `RDY` count of 1 (see [RDY State](https://nsq.io/clients/building_client_libraries.html#rdy_state)).
3.  Reconnection.  客户端库应按照下述方案自动处理重连接: 
    1.   如果消费者配置了一个专门的`nsqd`实例列表，则应该以指数回退的方式延迟重试尝试(即尝试在8s、16s、32s等最大时间内重新连接)来处理重连接 
    2.   如果将消费者配置为通过`nsqlookupd`发现实例，则应根据轮询间隔自动处理重连接( 例如，如果一个消费者从一个`nsqd`断开连接，客户端库应该只在后续的`nsqlookupd`轮询发现该实例时尝试重新连接 )。 这可以确保消费者可以知道`nsqd`被引入到拓扑中的和从拓扑中被删除(或失败)。 

### Feature Negotiation

1.  `IDENTIFY`命令可用于设置`nsqd`端元数据、修改客户端设置和协商功能。它满足两个需求: 

   1. In certain cases a client would like to modify how `nsqd` interacts with it (such as modifying a client’s heartbeat interval and enabling compression, TLS, output buffering, etc. - for a complete list see the [spec](https://nsq.io/clients/tcp_protocol_spec.html))
   2. `nsqd` responds to the `IDENTIFY` command with a JSON payload that includes important server side configuration values that the client should respect while interacting with the instance.

2.  连接后，根据用户的配置，客户端库应该发送一个`IDENTIFY`命令，其主体是一个JSON载荷: 

   ```json
   {
       "client_id": "metrics_increment",
       "hostname": "app01.bitly.net",
       "heartbeat_interval": 30000,
       "feature_negotiation": true
   }
   ```

3.  `feature_negotiation`字段表示客户端可以接受返回一个JSON有效负载 。 `client_id`和 `hostname `是`nsqd`(和`nsqadmin`)用来标识客户机的任意文本字段。 `heartbeat_interval`根据每个客户端配置心跳间隔。 

4.  如果nsqd不支持特性协商(在nsqd v0.2.20+中引入)，则`nsqd`将响应`OK`，否则: 

   ```json
   {
       "max_rdy_count": 2500,
       "version": "0.2.20-alpha"
   }
   ```

5. More detail on the use of the `max_rdy_count` field is in the [RDY State](https://nsq.io/clients/building_client_libraries.html#rdy_state) section.

### Data Flow and Heartbeats

1. 一旦消费者处于订阅状态，NSQ协议中的数据流就是异步的。 对于消费者来说，这意味着为了构建真正健壮和高性能的客户端库，应该使用异步网络IO循环和/或“线程”来构建它们 ( 双引号用于表示操作系统级线程和用户级线程，比如协同程序 )

2.  此外，客户端还需要响应它们所连接的nsqd实例的周期性心跳。 默认情况下，每隔30秒发生一次。 客户端可以使用任何命令进行响应，但是按照惯例，最简单的方法是在接收到心跳时使用`NOP`进行响应。 See the [protocol spec](https://nsq.io/clients/tcp_protocol_spec.html) for specifics on how to identify heartbeats. 

3.  一个“线程”应该专门用于从TCP套接字中读取数据，从帧中解包数据，并执行多路复用逻辑来路由数据。 这也是处理心跳的最佳地点。  At the lowest level, reading the protocol involves the following sequential steps:

   1. read 4 byte big endian uint32 size
   2. read size bytes data
   3. unpack data
   4. …
   5. profit
   6. goto 1

4. ### A Brief  Interlude on Errors

    由于其异步性，需要进行一些额外的状态跟踪，以便将协议错误与生成它们的命令关联起来。我们采用了“快速失败”的方法，因此协议级的绝大多数错误处理都是致命的。  这意味着，如果客户端发送了一个无效的命令(或使自己进入无效状态)，它所连接的`nsqd`实例将通过强制关闭连接(如果可能，还将向客户端发送一个错误)来保护自己(和系统)。 这样的处理， 再加上上面提到的连接处理，将使系统更加健壮和稳定。 

    唯一不会致命的错误是: 

      	-  `E_FIN_FAILED` - a `FIN` command for an invalid message ID 
              	-   `E_REQ_FAILED` - a `REQ` command for an invalid message ID 
                    	-   `E_TOUCH_FAILED` - a `TOUCH` command for an invalid message ID 

    因为这些错误通常是时间问题，所以它们不会被认为是致命的。  这些情况通常发生在消息在`nsqd`端超时并重新排队并传递给另一个消费者时。  原接收者不再允许代表该消息进行回复。 

### Message Handling

1.  当IO循环解包包含消息的数据帧时，它应该将该消息路由到配置的处理程序进行处理。 
2.  发送消息的`nsqd`期望在其配置的消息超时(默认为60秒)内收到回复。有几种可能的情况: 
   1. The handler indicates that the message was processed successfully.
   2. The handler indicates that the message processing was unsuccessful.
   3. The handler decides that it needs more time to process the message.
   4. The in-flight timeout expires and `nsqd` automatically re-queues the message.
3.  在前三种情况下，客户端库应该代表消费者发送适当的命令(分别是FIN、REQ和TOUCH)。 
4.  `FIN`命令是其中最简单的一个。它告诉`nsqd`可以安全地丢弃消息。`FIN`还可以用于丢弃不想处理或重试的消息。 
5.  `REQ`命令告诉`nsqd`消息应该重新排队(使用一个可选参数指定延迟额外的时间)。  如果消费者未指定可选参数，则客户端库应根据处理消息的尝试次数自动计算持续时间(多次通常就足够了)。  客户端库应该丢弃超过配置的最大尝试的消息。 发生这种情况时，应执行用户提供的回调以通知并启用特殊处理。
6.  如果消息处理程序需要的时间比配置的消息超时时间更多，那么可以使用`TOUCH`命令重置`nsqd`端的计时器。  这可以重复执行，直到消息是`FIN`或`REQ`，或者到达`nsqd`配置的`max_msg_timeout`。  客户端库永远不应该代表消息者自动  `TOUCH`  
7.  如果发送的`nsqd`实例没有收到响应，消息将超时并自动重新排队以交付给可用的消费者。 
8.  最后，每个消息的一个属性是尝试次数。客户端库应该将此值与配置的最大值进行比较，并丢弃超过此值的消息。  当一条消息被丢弃时，应该触发一个回调。 此回调的典型默认实现可能包括写入磁盘上的目录、日志记录等。 用户应该能够覆盖默认处理。  

### RDY State

因为消息是从`nsqd`推送给消费者的，所以我们需要一种方法来管理用户空间中的数据流，而不是依赖于底层的TCP语义。消费者的`RDY`状态是NSQ的流控制机制。

As outlined in the [configuration section](https://nsq.io/clients/building_client_libraries.html#configuration), a consumer is configured with a `max_in_flight`.  这是一个并发性和性能的旋钮，例如，一些下游系统能够更容易地批处理消息，并从更高的` max-in-flight `中获益。

 当使用者连接到`nsqd`(并订阅)时，它的初始`RDY`状态为0。将没有任何消息被发送。

  客户端库有一些职责: 

```
bootstrap and evenly distribute the configured `max_in_flight` to all connections.
never allow the aggregate sum of `RDY` counts for all connections (`total_rdy_count`) to exceed the configured `max_in_flight`.
never exceed the per connection `nsqd` configured `max_rdy_count`.
expose an API method to reliably indicate message flow starvation
```

1. ### Bootstrap and Distribution

    在为连接选择适当的RDY计数(以便均匀分配max_in_flight)时，有几个注意事项: 

    - the # of connections is dynamic, often times not even known in advance (ie. when discovering nsqd via nsqlookupd).
    - max_in_flight may be lower than your number of connections

    为了启动消息流，客户端库需要发送一个初始RDY计数。 由于通常不提前知道连接的最终数量，所以它应该以值1开始，这样客户端库就不会不公平地偏爱第一个连接。 

    此外，在处理每个消息之后，客户端库应该评估是否应该更新RDY状态。 如果当前值为0，或者小于最近发送值的25%，则应触发更新(TODO 为什么是这个触发条件)。

    客户端库应该始终尝试在所有连接之间均匀分布RDY计数。通常，这是通过`max_in_flight / num_conns`实现的。  

    但是，当`max_in_flight < num_conns`时，这个简单的公式是不够的。  在这种状态下，客户端库应该执行动态运行时评估` connected `nsqd` "liveness" `，方法是测量它上次通过给定连接接收消息以来的持续时间。 After a configurable expiration, it should *re-distribute* whatever `RDY` count is available to a new (random) set of `nsqd`. By doing this, you guarantee that you’ll (eventually) find `nsqd` with messages. Clearly this has a latency impact. 

2. ### Maintaining `max_in_flight`

    客户端库应该为给定消费者的最大消息数量维护一个上限。  具体来说，每个连接的RDY计数的总和不应该超过配置的`max_in_flight `

     下面是Python中的示例代码，用于确定建议的RDY计数对给定的连接是否有效: 

    ```python
    def send_ready(reader, conn, count):
        if (reader.total_ready_count + count) > reader.max_in_flight:
            return
    
        conn.send_ready(count)
        conn.rdy_count = count
        reader.total_ready_count += count
    ```

    

3. ### `nsqd` Max RDY Count

    Each `nsqd` is configurable with a `--max-rdy-count` (see [feature negotiation](https://nsq.io/clients/building_client_libraries.html#feature_negotiation) for more information on the handshake a consumer can perform to ascertain this value). If the consumer sends a `RDY` count that is outside of the acceptable range its connection will be forcefully closed. For backwards compatibility, this value should be assumed to be `2500` if the `nsqd` instance does not support [feature negotiation](https://nsq.io/clients/building_client_libraries.html#feature_negotiation). 

4. ### Message Flow Starvation

    客户端库应该提供一个API方法来指示消息流饥饿。对于消费者(在其消息处理程序中)来说，仅仅比较它们拥有的正在运行的消息数量与它们配置的`max_in_flight`的数量以决定“处理一批”是不够的((在其消息处理程序中))。有两种情况下这是有问题的: 

    1. When consumers configure `max_in_flight > 1`, due to variable `num_conns`, there are cases where `max_in_flight` is not evenly divisible by `num_conns`. Because the contract states that you should never *exceed* `max_in_flight`, you must round down, and you end up with cases where the sum of all `RDY` counts is less than `max_in_flight`.
    2. Consider the case where only a subset of `nsqd` have messages. Because of the expected [even distribution](https://nsq.io/clients/building_client_libraries.html#bootstrap_and_distribution) of `RDY` count, those active `nsqd` only have a fraction of the configured `max_in_flight`.

     在这两种情况下，消费者实际上永远不会收到`max_in_flight `的消息。因此，客户端库应该公开一个方法 `is_starved`  ，该方法将评估是否有任何连接被饿死，如下所示: 

    ```python
    def is_starved(conns):
        for c in conns:
            # the constant 0.85 is designed to *anticipate* starvation rather than wait for it
            if c.in_flight > 0 and c.in_flight >= (c.last_ready * 0.85):
                return True
        return False
    ```

     消息处理程序应该使用`is_starved`  方法来可靠地确定何时处理一批消息。 

### Backoff

1.  当消息处理失败时该做什么是一个复杂的问题。消息处理一节详细描述了客户端库的行为，这些行为会将失败消息的处理延迟一段时间(逐渐增加时间间隔)。  另一个难题是是否减少吞吐量。这两个功能之间的相互作用对于整个系统的稳定性至关重要。 

2.  通过降低处理速度或“后退”(backoff)，消费者允许下游系统从瞬时故障中恢复。然而，这种行为应该是可配置的，因为它并不总是可取的，例如延迟是优先级高的情况。 

3.  应该通过将`RDY ` `0`发送到适当的`nsqd`来实现回退，从而停止消息流。  保持这种状态的时间应该根据重复故障的次数(指数级)来计算。  类似地，成功的处理应该减少这种持续时间，直到读取器不再处于回退状态。 

4.  当`reader`处于回退状态时，超时过期后，客户机库应该只发送`RDY 1`，而不考虑`max_in_flight`。 这是在返回全速之前有效地“试水”  。 此外，在回退超时期间，客户端库应该忽略与计算回退持续时间有关的任何成功或失败结果 ( 也就是说，它应该只考虑每个回退超时的一个结果 )

   ![tumblr_inline_mmjev3stkE1qz4rgp](F:\PersonPorject\book-notes\NSQ\img\tumblr_inline_mmjev3stkE1qz4rgp.png)

### Encryption/Compression

1.  NSQ通过`IDENTIFY`命令支持加密和/或压缩特性协商。 TLS用于加密。  Snappy和DEFLATE都支持压缩。Snappy是一个第三方库，但是大多数语言都有对DEFLATE的原生支持。  

2.  当收到`IDENTIFY`响应时，你通过`tls_v1`标志请求`TLS`，你会得到类似以下JSON: 

   ```json
   {
       "deflate": false,
       "deflate_level": 0,
       "max_deflate_level": 6,
       "max_msg_timeout": 900000,
       "max_rdy_count": 2500,
       "msg_timeout": 60000,
       "sample_rate": 0,
       "snappy": true,
       "tls_v1": true,
       "version": "0.2.28"
   }
   ```

    确认`tls_v1`设置为`true`(表示服务器支持TLS)之后，启动TLS握手(例如，在Python中使用` ssl.wrap_socket` 调用)，然后才发送或接收其他任何东西。 在成功的TLS握手之后，您必须立即读取一个加密的NSQ `OK`响应。

3.  这些压缩特性是相互排斥的。 
4.  在完成加密/压缩之前阻止缓冲非常重要，或者在协商特性时确保读空非常重要 

### Bringing It All Together

NSQ集群的各个组件之间的交互协同工作，提供了一个平台，在这个平台上构建健壮、高性能和稳定的基础设施。我们希望本指南能让您了解客户端的角色有多重要。 

在实际实现所有这些方面，我们将`pynsq`和`go-nsq`作为我们的参考代码库。`pynsq`的结构可以分为三个核心部分: 

- `Message` - a high-level message object, which exposes stateful methods for responding to `nsqd` (`FIN`, `REQ`, `TOUCH`, etc.) as well as metadata such as attempts and timestamp.
- `Connection` - a high-level wrapper around a TCP connection to a specific `nsqd`, which has knowledge of in flight messages, its `RDY` state, negotiated features, and various timings.
- `Consumer` - the front-facing API a user interacts with, which handles discovery, creates connections (and subscribes), bootstraps and manages `RDY` state, parses raw incoming data, creates `Message` objects, and dispatches messages to handlers.
- `Producer` - the front-facing API a user interacts with, which handles publishing.



# CLIENTS (TCP) 



